{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1: Movies on Netflix, Prime Video, Hulu and Disney+\n",
    "\n",
    "* Source: Kaggle  \n",
    "* Link: [https://www.kaggle.com/datasets/...](https://www.kaggle.com/datasets/ruchi798/movies-on-netflix-prime-video-hulu-and-disney  )\n",
    "* Format: CSV file    \n",
    "* Size: ~1 MB  \n",
    "\n",
    "**Details:** This dataset includes the fields, movie title, release year, age, rotten tomatoes, and availability on Netflix, Prime Video, Hulu, and Disney+, and Type (Movie: 0 TV Show: 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"ruchi798/movies-on-netflix-prime-video-hulu-and-disney\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Shows first few columns of the dataset \n",
    "df_1 = pd.read_csv(path + '/MoviesOnStreamingPlatforms.csv')\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataframe info\n",
    "print(\"Number of Rows: \", df_1.shape[0])\n",
    "print(\"Number of Columns: \", df_1.shape[1])\n",
    "print(\"\\nColumn info:\\n\")\n",
    "print(df_1.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA):\n",
    "*   Visualize feature distributions\n",
    "*   Create correlation heatmaps for numerical features\n",
    "*   Explore relationships between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Feature Distributions\n",
    "df_1['Rotten Tomatoes'] = df_1['Rotten Tomatoes'].str.split('/').str[0].astype(float)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(df_1['Year'], bins=20, kde=True)\n",
    "plt.title('Distribution of Year')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.countplot(data=df_1, x='Age', order=df_1['Age'].value_counts().index)\n",
    "plt.title('Distribution of Age Ratings')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(df_1['Rotten Tomatoes'], bins=20, kde=True)\n",
    "plt.title('Distribution of Rotten Tomatoes Scores')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap for Numerical Features ####\n",
    "correlation_matrix = df_1[['Year', 'Rotten Tomatoes', 'Netflix', 'Hulu', 'Prime Video', 'Disney+']].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Relationships Between Features\n",
    "\n",
    "# Rotten Tomatoes Score vs. Streaming Platforms\n",
    "# Use: Recommend highly rated movies based on the userâ€™s subscribed platforms (e.g., Netflix, Prime Video).\n",
    "df_1['Platforms'] = df_1[['Netflix', 'Hulu', 'Prime Video', 'Disney+']].sum(axis=1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_1, x='Platforms', y='Rotten Tomatoes', hue='Age', palette='Set1')\n",
    "plt.title('Rotten Tomatoes Scores vs Number of Streaming Platforms')\n",
    "plt.xlabel('Number of Streaming Platforms')\n",
    "plt.ylabel('Rotten Tomatoes Score')\n",
    "plt.legend(title='Age Rating')\n",
    "plt.show()\n",
    "\n",
    "# Rotten Tomatoes Score vs. Release Year\n",
    "# Use: Recommend highly rated movies within certain eras that the user prefers\n",
    "df_1 = df_1.copy()\n",
    "df_1.loc[:, 'Rotten Tomatoes'] = df_1['Rotten Tomatoes'].astype(str).str.split('/').str[0]\n",
    "df_1.loc[:, 'Rotten Tomatoes'] = pd.to_numeric(df_1['Rotten Tomatoes'], errors='coerce')\n",
    "df_1 = df_1.dropna(subset=['Rotten Tomatoes', 'Year'])\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Year', y='Rotten Tomatoes', data=df_1, alpha=0.6, color='blue')\n",
    "plt.title('Rotten Tomatoes Score vs. Release Year')\n",
    "plt.xlabel('Release Year')\n",
    "plt.ylabel('Rotten Tomatoes Score')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2: Full TMDB Movies Dataset 2024  \n",
    "\n",
    "* Source: Kaggle\n",
    "* Link: [Here](https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies)\n",
    "* Format: CSV file\n",
    "* Size: ~500 MB, containing extensive information on nearly 1 million movies, including genres, cast, crew, keywords, and other metadata.  \n",
    "\n",
    "**Details:** This dataset provides a rich set of attributes for each movie. Important features include genres, movie synopsis, director, and popularity score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"asaniczka/tmdb-movies-dataset-2023-930k-movies\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows first few columns of the dataset \n",
    "df_2 = pd.read_csv(path + '/TMDB_movie_dataset_v11.csv')\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataframe info\n",
    "print(\"Number of Rows: \", df_2.shape[0])\n",
    "print(\"Number of Columns: \", df_2.shape[1])\n",
    "print(\"\\nColumn info:\\n\")\n",
    "print(df_2.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA): \n",
    "*   Visualize feature distributions\n",
    "*   Create correlation heatmaps for numerical features\n",
    "*   Explore relationships between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Feature Distributions\n",
    "\n",
    "# Distribution of IMDb (vote_average) Scores\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_2['vote_average'], bins=20, kde=True, color='teal')\n",
    "plt.title('Distribution of IMDb Scores')\n",
    "plt.xlabel('IMDb Score (Vote Average)')\n",
    "\n",
    "# Distribution of Movies by genre\n",
    "df_genres = df_2.assign(genres=df_2['genres'].str.split(',')).explode('genres')\n",
    "\n",
    "df_genres['genres'] = df_genres['genres'].str.strip()\n",
    "df_genres = df_genres[df_genres['genres'].notna() & (df_genres['genres'] != '')]\n",
    "\n",
    "unique_genres = df_genres['genres'].value_counts().index\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.countplot(data=df_genres, x='genres', order=unique_genres, legend=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Number of Movies by Genre')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Number of Movies')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of Movies by release year\n",
    "plt.figure(figsize=(15, 5))\n",
    "df_2['release_year'] = pd.to_datetime(df_2['release_date'], errors='coerce').dt.year\n",
    "sns.histplot(df_2['release_year'].dropna(), bins=20, kde=True, color='coral')\n",
    "plt.title('Number of Movies by Release Year')\n",
    "plt.xlabel('Release Year')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Correlation Heatmap for Numerical Features\n",
    "df_encoded = df_2.copy()\n",
    "df_encoded['adult'] = df_encoded['adult'].astype(int)\n",
    "df_encoded['release_year'] = pd.to_datetime(df_encoded['release_date']).dt.year\n",
    "df_encoded = df_encoded.drop(columns=['status', 'release_date', 'backdrop_path', 'poster_path', 'original_title', 'overview', 'keywords', 'production_companies', 'production_countries', 'spoken_languages'], errors='ignore')\n",
    "numerical_features = df_encoded.select_dtypes(include=['float64', 'int64'])\n",
    "correlation_matrix = numerical_features.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', square=True, linewidths=0.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Relationships Between Features\n",
    "\n",
    "# IMDb Scores vs. Genres\n",
    "top_genres = df_2['genres'].value_counts().nlargest(10).index\n",
    "filtered_df = df_2[df_2['genres'].isin(top_genres)]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.boxplot(data=filtered_df, x='genres', y='vote_average', palette='viridis', hue='genres')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('IMDb Scores Distribution Across Top 10 Genres')\n",
    "plt.xlabel('Genres')\n",
    "plt.ylabel('IMDb Score')\n",
    "plt.show()\n",
    "\n",
    "# IMDb Scores vs. Revenue\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_2, x='revenue', y='vote_average', alpha=0.6)\n",
    "plt.title('IMDb Scores vs. Revenue')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Revenue (log scale)')\n",
    "plt.ylabel('IMDb Score')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Release Year vs. IMDb Scores\n",
    "df_2['release_year'] = pd.to_datetime(df_2['release_date']).dt.year\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(data=df_2, x='release_year', y='vote_average', estimator='mean')\n",
    "plt.title('Average IMDb Score Over Years')\n",
    "plt.xlabel('Release Year')\n",
    "plt.ylabel('Average IMDb Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the 2 Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_1['title_lower'] = df_1['Title'].str.lower()\n",
    "df_2['title_lower'] = df_2['title'].str.lower()\n",
    "\n",
    "df_2.dropna(subset=['release_date'], inplace=True)\n",
    "df_2['Year'] = pd.to_datetime(df_2['release_date']).dt.year\n",
    "df_2['Year'] = df_2['Year'].astype(int)\n",
    "\n",
    "df_merged = df_1.merge(\n",
    "    df_2[['title_lower', 'genres', 'keywords', 'overview', 'production_countries', 'Year', 'spoken_languages']],\n",
    "    on=['title_lower', 'Year'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "df_merged.drop(columns=['title_lower'], inplace=True)\n",
    "\n",
    "# New Rows vs Columns\n",
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows first few columns of the new dataset \n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Recommendations using KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accomplish this, lets make a tag column for our text data, and then drop all unnesesary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[['genres', 'keywords', 'overview', 'production_countries', 'spoken_languages']] = df_merged[['genres', 'keywords', 'overview', 'production_countries', 'spoken_languages']].fillna('')\n",
    "\n",
    "df_merged['tags'] = (\n",
    "    df_merged['genres'] + ' ' +\n",
    "    df_merged['keywords'] + ' ' +\n",
    "    df_merged['overview'] + ' ' +\n",
    "    df_merged['production_countries'] + ' ' +\n",
    "    df_merged['spoken_languages']\n",
    ")\n",
    "\n",
    "df_merged['tags'] = df_merged['tags'].apply(\n",
    "    lambda x: re.sub(r'\\s+', ' ', x.strip())\n",
    ")\n",
    "\n",
    "df_merged.drop(columns=['genres', 'keywords', 'overview', 'production_countries', 'spoken_languages'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we make our TF-IDF Vectorizer.\n",
    "\n",
    "TF-IDF is a numerical representation of text that reflects how important a word is in a document relative to the entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "tfidf_matrix = vectorizer.fit_transform(df_merged['tags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we make our KNN Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "knn.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the function to get the nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recs(movie_title, n_recs=5):\n",
    "  try:\n",
    "    index = df_merged[df_merged['Title'].str.lower() == movie_title.lower()].index[0]\n",
    "  except IndexError:\n",
    "    print(\"Movie not found\")\n",
    "    return []\n",
    "\n",
    "  movie_vector = tfidf_matrix[index]\n",
    "\n",
    "  distances, indices = knn.kneighbors(movie_vector, n_neighbors=n_recs)\n",
    "\n",
    "  recommended_movies = [df_merged.iloc[i]['Title'] for i in indices.flatten()[1:]]\n",
    "\n",
    "  return recommended_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets test our function and see how well it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_to_test = [\n",
    "    \"Limitless\",      # Sci-Fi\n",
    "    \"Mad Max\",        # Action\n",
    "    \"Love actually\",  # Romance\n",
    "    \"The Conjuring\",  # Horror\n",
    "    \"Superbad\",       # Comedy\n",
    "]\n",
    "\n",
    "for movie in genres_to_test:\n",
    "    print(f\"Recommendations for '{movie}':\")\n",
    "    print(get_recs(movie, n_recs=5))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, now lets try to evaluate how this model is actually doing - and how similar these recomendations actually are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(movie_title, n_recs=5):\n",
    "  try:\n",
    "      index = df_merged[df_merged['Title'].str.lower() == movie_title.lower()].index[0]\n",
    "  except IndexError:\n",
    "      print(\"Movie not found\")\n",
    "      return\n",
    "\n",
    "  movie_vector = tfidf_matrix[index]\n",
    "  distances, indices = knn.kneighbors(movie_vector, n_neighbors=n_recs)\n",
    "\n",
    "  recommend_titles = [df_merged.iloc[i]['Title'] for i in indices.flatten()]\n",
    "  distances = distances.flatten()\n",
    "\n",
    "  sns.heatmap(\n",
    "      [distances],\n",
    "      annot=True,\n",
    "      fmt=\".2f\",\n",
    "      xticklabels=recommend_titles,\n",
    "      yticklabels=[\"Cosine Distances\"],\n",
    "      cmap=\"coolwarm\"\n",
    "  )\n",
    "\n",
    "  plt.title(f\"Distances from '{movie_title}' to recommendad movies\")\n",
    "  plt.show()\n",
    "\n",
    "genres_to_test = [\n",
    "    \"Limitless\",      # Sci-Fi\n",
    "    \"Mad Max\",        # Action\n",
    "    \"Love actually\",  # Romance\n",
    "    \"The Conjuring\",  # Horror\n",
    "    \"Superbad\",       # Comedy\n",
    "]\n",
    "\n",
    "for movie in genres_to_test:\n",
    "    print(f\"Recommendations for '{movie}':\")\n",
    "    print(get_recs(movie, n_recs=5))\n",
    "    plot_heatmap(movie, n_recs=5)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad, lets see if we can get the 2D project of the distances, using principle component analysis (PCA) or the t-distributed stochastic neighbor embedding (t-SNE).\n",
    "\n",
    "T-SNE is just a way to visualize high-dimensional data by placing each data point in a two- or three-dimensional map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_space(n_movies=100):\n",
    "  reduced_matrix = (TSNE(n_components=2, random_state=42).fit_transform(tfidf_matrix[:n_movies].toarray()))\n",
    "\n",
    "  plt.figure(figsize=(12, 8))\n",
    "  plt.scatter(reduced_matrix[:, 0], reduced_matrix[:, 1], alpha=0.7)\n",
    "\n",
    "  for i, title in enumerate(df_merged['Title'][:n_movies]):\n",
    "      plt.text(reduced_matrix[i, 0], reduced_matrix[i, 1], title, fontsize=8)\n",
    "\n",
    "  plt.title(f\"Movie t-SNE Space Visualization\")\n",
    "  plt.xlabel(\"Component 1\")\n",
    "  plt.ylabel(\"Component 2\")\n",
    "  plt.show()\n",
    "\n",
    "def plot_PCA_space(n_movies=100):\n",
    "  reduced_matrix = (PCA(n_components=2, random_state=42).fit_transform(tfidf_matrix[:n_movies].toarray()))\n",
    "\n",
    "  plt.figure(figsize=(12, 8))\n",
    "  plt.scatter(reduced_matrix[:, 0], reduced_matrix[:, 1], alpha=0.7)\n",
    "\n",
    "  for i, title in enumerate(df_merged['Title'][:n_movies]):\n",
    "      plt.text(reduced_matrix[i, 0], reduced_matrix[i, 1], title, fontsize=8)\n",
    "\n",
    "  plt.title(f\"Movie PCA Space Visualization\")\n",
    "  plt.xlabel(\"Component 1\")\n",
    "  plt.ylabel(\"Component 2\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne_space()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_PCA_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Recommendations using K-Means Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "df_pca = pca.fit_transform(df.drop(columns=['Cluster']))\n",
    "\n",
    "plt.scatter(df_pca[:, 0], df_pca[:, 1], c=df['Cluster'], cmap='viridis')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('K-Means Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reference['Cluster'] = df['Cluster']\n",
    "\n",
    "for cluster in range(k):\n",
    "    print(f\"\\nCluster {cluster}\")\n",
    "    print(df_reference[df_reference['Cluster'] == cluster][['Title', 'Year', 'Age', 'Rotten Tomatoes', 'tags']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Recommendaitons using K-Means(++) Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designated lists of options\n",
    "ages = [\"7+\", \"13+\", \"16+\", \"18+\"]\n",
    "platforms = [\"Netflix\", \"Hulu\", \"Prime Video\", \"Disney+\"]\n",
    "regions = [\"United States of America\", \"India\", \"United Kingdom\", \"China\", \"Australia\", \"Canada\", \"France\", \"Germany\", \"Italy\", \"New Zealand\"]\n",
    "languages = [\"English\", \"Spanish\", \"French\", \"German\", \"Japanese\", \"Indian\", \"Korean\", \"Mandarin\", \"Hindi\", \"Arabic\", \"Italian\"]\n",
    "\n",
    "# Function to get validated input\n",
    "def get_input(prompt, options):\n",
    "    while True:\n",
    "        print(f\"Options: {', '.join(options)}\")\n",
    "        choice = input(prompt)\n",
    "        if choice in options:\n",
    "            return choice\n",
    "        else:\n",
    "            print(\"Invalid choice. Please select from the options above.\")\n",
    "\n",
    "# User inputs with validation\n",
    "age = get_input(\"Please enter your age: \", ages)\n",
    "platform = get_input(\"Please enter your streaming platform: \", platforms)\n",
    "region = get_input(\"Please enter your region: \", regions)\n",
    "language = get_input(\"Please enter your language: \", languages)\n",
    "\n",
    "# Display user selections\n",
    "print(f\"\\nYou selected:\")\n",
    "print(f\"Age: {age}\")\n",
    "print(f\"Platform: {platform}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"language: {language}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reference = df_merged.copy()\n",
    "df = df_merged.drop(columns=['Unnamed: 0', 'ID', 'Title', 'Rotten Tomatoes']) # CAN ALSO REMOVE ROTTEN TOMATOES!\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['Age', 'Type', 'Platforms']\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=50)  # Limit to top 50 words\n",
    "tags_tfidf = tfidf.fit_transform(df['tags']).toarray()\n",
    "tags_df = pd.DataFrame(tags_tfidf, columns=tfidf.get_feature_names_out())\n",
    "df = pd.concat([df.drop(columns=['tags']), tags_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[['Year']] = scaler.fit_transform(df[['Year']]) # CAN ALSO REMOVE ROTTEN TOMATOES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 15\n",
    "train_df, validation_df = train_test_split(df, train_size=0.8, random_state=42)\n",
    "kmeans_plus = KMeans(n_clusters=k, init='k-means++', random_state=39)\n",
    "df['Cluster'] = kmeans_plus.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, visualize the clusters using PCA to reduce to two dimensions\n",
    "pca = PCA(n_components=2)\n",
    "df_pca = pca.fit_transform(df.drop(columns=['Cluster']))\n",
    "\n",
    "plt.scatter(df_pca[:, 0], df_pca[:, 1], c=df['Cluster'], cmap='viridis')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('K-Means++ Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to reduce dimensions to 3 for 3D visualization\n",
    "pca = PCA(n_components=3)\n",
    "df_pca = pca.fit_transform(df.drop(columns=['Cluster']))\n",
    "\n",
    "# Create a 3D scatter plot of the clusters\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(df_pca[:, 0], df_pca[:, 1], df_pca[:, 2], c=df['Cluster'], cmap='viridis', marker='o')\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('PCA Component 1')\n",
    "ax.set_ylabel('PCA Component 2')\n",
    "ax.set_zlabel('PCA Component 3')\n",
    "ax.set_title('K-Means++ Clustering in 3D')\n",
    "\n",
    "# Add a legend (using color bar)\n",
    "cbar = plt.colorbar(scatter, ax=ax, pad=0.1, orientation='vertical')\n",
    "cbar.set_label('Cluster Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reference['Cluster'] = df['Cluster']\n",
    "for cluster in range(k):\n",
    "    print(f\"\\nCluster {cluster}\")\n",
    "    print(df_reference[df_reference['Cluster'] == cluster][['Title', 'Year', 'Age', 'Rotten Tomatoes']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(movie_title, n_recommendations=5):\n",
    "    # Find the cluster of the given movie\n",
    "    if movie_title not in df_reference['Title'].values:\n",
    "        return \"Movie not found in database.\"\n",
    "    else:\n",
    "        # print(\"Reccs for: \", df_reference.loc[df_reference['Title'] == movie_title])\n",
    "        print(\"Reccs for: \", movie_title)\n",
    "\n",
    "    cluster_label = df_reference[df_reference['Title'] == movie_title]['Cluster'].values[0]\n",
    "\n",
    "    # Get other movies in the same cluster\n",
    "    recommendations = df_reference[(df_reference['Cluster'] == cluster_label) & (df_reference['Title'] != movie_title)]\n",
    "    recommendations = recommendations.drop_duplicates(subset='Title')\n",
    "\n",
    "    # Limit to n recommendations\n",
    "    return recommendations[['Title', 'Netflix', 'Hulu', 'Prime Video', 'Disney+', 'tags', 'Year', 'Age', 'Rotten Tomatoes']].head(n_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_movies('Guardians of the Galaxy', 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
